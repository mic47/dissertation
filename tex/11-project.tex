\chapter{PhD project}
%Poznamka pre seba -- toto chcem asi kratsie ako som to zacal pisat. Celkovo by
%o mohlo mat tak par stran

We want to study decoding algorithms for hidden Markov models and pair hidden
Markov models (and their variants) and to apply them in comparative analysis
of biological sequences. We divide our goals into three areas.
\begin{itemize}
\item Study of efficient implementations of existing algorithm for HMMs and
pHMMs, analysis of their expected computational complexity and design of  new
improvements.

\item Study of different decoding algorithms (expressed using the highest
expected gain framework) for HMMs and pHMMs. Analysis of their computational
complexity, and their performance in particular application domains.    

\item Application of pHMMs to improve existing pairwise alignment
tools. Design of new decoding algorithms and pHMMs that take into
account additional informations about structure of biological of sequences.
\end{itemize}
In the following sections we describe problems we want to solve, and propose several
approaches for solving those problems.


\section{Improvements and Analysis of Existing Algorithms}

It has been shown that eunning time and space of traditional algorithms for working with HMMs can be
improved by various techniques. In section \ref{SECTION:ALGORITHMICIMPROVEMENTS}
we discussed several such techniques, including checkpointing
\cite{Grice1997}, compression \cite{Lifshits2009} or by release of memory which
is no longer necessary \cite{Sramek2007}. We plan to address open quations in
the analysis of such improvements and to propose new techniques.

%There is space improvements and analysis of improvements
%of basic algorithm for HMMs.

\subsection{On-line Viterbi algorithm}

In section \ref{SECTION:ONLINEVITERBI} we discussed the  On-line Viterbi
algorithm. The On-line Viterbi algorithm does not store the full matrix of back-links
$B$, instead it keeps a compressed forest
composed of those parts of the state paths that can be in the most
probable state path. As soon as the algorithm detects that some parts cannot be
in the most probable state path, it discards them. The original paper
contains analysis of this algorithm for two-state HMMs. With such
HMM, the expected memory requirements is $O(h\log n)$ where $h$ is a constant
specific for a particular HMM \cite{Sramek2007}. Šrámek {\it et al.} conducted experimental
evaluation of the expected memory complexity and conjectured that the expected
memory complexity of this algorithm is polylogarithmic in the length of the
sequence. However, analytical results for general HMMs are not known.

Our goal is to characterize classes of HMMs for which  the expected memory
complexity of the on-line algorithm will be logarithmic or polylogarithmic in
the length of the input sequence under the assumptions that the input sequence is
sampled from the model or that symbols of the sequence were sampled
independently from certain (for example uniform) distribution.

%Da sa studovat aj worstcase, ale to nepisem
%We want to characterize classes of HMMs, on which average memory complexity
%of the On-line Viterbi algorithm is logarithmic or polylogarithmic. Average
%memory complexity is of the On-line Viterbi algorithm is computed either on the
%random sequence or if the sequence comes from the model. Interesting will be
%also to study worst case complexity for certain classes of HMMs.

One possible approach to solve this problem is to search for the ``synchronizing
sequences''. \todo{este sa zamysli nad touto formulaciou} 
Sequence $s\in\Sigma^*$ is a synchronizing sequence if there exists
state $v$ and position $p$ in the sequence $s$, such that for all sequences
$x\in \Sigma^*$ and states $u$ satisfies $\pi_u[{p+|x|}]=v$ where $\pi_u$ is the
most probable state path of the sequence $xs$ ending
in the state $u$. Intuitively, synchronizing sequence force the Viterbi algorithm
to pass through a certain state and therefore for any sequence $y\in \Sigma^*$,
the most probable state path $\pi_{xsy}$ of sequence $xsy$ has the same prefix
$\pi_{xsy}[:|x|]$. Therefore the On-line Viterbi algorithm after passing
sequence $s$ will print (and discard) the most probable state path for prefix
$x$ of $xs$. 

If an HMM has a synchronizing sequence and $f(n)$ is the expected maximal distance
between two synchronizing strings in a sequence of length $n$ (sampled from
some distribution $D$) then the On-line Viterbi algorithm will have the expected memory
complexity $O(f(n)m)$ where $m$ is the number of states.

Our goal is to develop criterion of the existence of the synchronizing string
for given HMM and to compute an upper bound of the $f(n)$, the expected maximal
distance between two synchronizing strings in the sequence of length $n$.
%To finish analysis of this algorithm, we need to find the criterion for the
%\todo{preformulovat} existence of the synchronizing string for given HMM and
%develop method of computing the upper bound for the $f(n)$, the expected
%maximal distance between two synchronizing strings in the sequence of length
%$n$.


\subsection{Mixing Times}

\def\tmix{t_{mix}(\epsilon)}
We propose technique to improve memory complexity of the
Posterior decoding using approximations based on the theory of mixing times.
From HMM $H$ we compute a threshold  $T$ (more details
bellow).  We divide the input sequence $X$ of length $n$ into $l$ overlapping
subsequences $x_i=X[2iT:(2i+3)T]$ (for simplicity we assume that $n=(2l+1)T$).  
We run the Posterior decoding for each subsequence $x_i$ independently, obtaining state path
$\pi_i$. If $m$ is the number of states of $H$
then this will take $O(nm^2)$ time since the total length of sequences $x_i$ is
less than $3n$.  We construct the optimal state path $\pi$ by middle points of
the partial paths $\pi_i$
\[\pi = \pi_0[:2T]
\pi_1[T:2T] \pi_2[T:2T] \dots \pi_{l-2}[T:2T] \pi_{l-1}[T:]\] where
$T=t_{mix}[\epsilon]$.
We conjecture that if $T$ is sufficiently high and the input
sequence $X$ was sampled from $H$, then with hight probability the reconstructed
state path $\pi$ is the state path that maximizes objective function of the
Posterior decoding.  Time complexity of this algorithm is $O(nm^2)$ and memory
complexity is $O(n+Tm)$ which can be considerable improvement over $O(\sqrt n
m)$ algorithm since $T$ is a constant specific for HMM but independent of $n$. However in practice $T$
can be too high.

As a threshold $T$, we can use is the mixing time $t_{\mix}$ defined it in the following way:
\[\tmix = \min_{i}\left\{ 
\left(\max_{\mu,\nu,X} || \prob{\pi[i] = \cdot\mid X[:i+1],H_\nu} - \prob{\pi[i] = \cdot\mid
X[:i+1],H_\mu}||_{TV}\right)\leq \epsilon
\right\}
\] 
\todo{koniec tohoto odstavca sa mi nepaci}
where $H_\mu$ and $H_\nu$ are HMMs created from $H$ by replacing initial
distribution with $H_\mu$ and $H_\nu$ respectively,
$X$ is a sequence
sampled from $H$ and $||\cdot||_{TV}$ is the total variation distance:
$||\mu-\nu||_{TV}=\frac12\sum_{x\in S}|\mu(x)-\mu(x)|$ where $\mu$ and $\nu$
are probability distribution over a finite set $S$.
Intuitively, after $\tmix$ steps the initial distribution does not matter, since
the total variation of the normalized forward variables $F[\tmix+i,\cdot]$
and the corresponding normalized forward variables of the original computation
of the Forward algorithm is less than $\epsilon$. Normalized forward variables
are forward variables multiplied by a constant so they sum up to one. 
Same holds for the backward variables $B$ and therefore the posterior
probabilities decoded in the middle of subsequence $x_i$ will be almost the same
if we were computing the posterior probabilities on the whole sequence $X$.

Mixing times were originally defined for Markov chains \cite{Levin2006}. Markov
chains are HMMs without emissions: the state path is observed, not hidden. We
want to extend the mixing times for HMMs and find way of estimation $\tmix$ for
a given HMM.

This technique can be also used to reduce memory complexity of HMM training and
to parallelize the Posterior decoding, the Forward algorithm and the
Training algorithms.

\section{Measures for decoding algorithms}

%Predpoklady co som uz vysvetlil:
% HMM, Viterbi, Posterior, most probable annotation, balls, herd, -- gain
% functions
The second area of our interest are different optimization criteria for decoding
HMMs expressed in the form of the highest expected gain framework (section
\ref{SECTION:HEG}) This framework generalizes decoding methods for HMMs. Recall
that decoding method is the method of obtaining an annotation of a sequence from
the sequence and the model. 

In the highest expected gain framework we characterize decoding algorithm by
gain function $f(\Lambda_1,\Lambda_2)$ defined on annotations. Given the
sequence $X$, we seek for an annotation $\Lambda$ of the sequence $X$ with the
highest expected gain \[\Lambda = \arg\max_{\Lambda} E_{\Lambda_X\mid
X,H}[f(\Lambda_X,\Lambda)] =
\sum_{\Lambda_X}f(\Lambda_X,\Lambda)\Pr\left(\Lambda_X\mid X,H\right) \]

%At first we briefly review the highest expected reward
%framework.
%
%Hidden Markov models define probability distribution over state paths $\pi$
%given sequence $X$ and model $H$: $\prob{\pi\mid X,H}$. Given annotation
%function $\lambda$, HMMs also defines probability distribution of annotations
%$\Lambda=\lambda(\pi)$ given sequence $X$: $\prob{\Lambda\mid X,H}$.  The state
%path (or an annotation) that generated a sequence $X$ is hidden.
%We will denote by
%the \firstUseOf{correct state path} of sequence $X$ the state path that
%generated $X$ and the \firstUseOf{correct annotation} is annotation of the
%correct state path. Our goal is to find the correct annotation/state path of
%given sequence $X$ or at least the good approximation of it.
%
%This is usually done by finding the most probable state path and taking it's
%annotation. However, in case of HMMs that have multiple path problem, 
%the most probable state path does not have to correspond to the most probable
%annotation. Additionally, even the most probable annotation does not have to
%give us useful approximation of the correct annotation. Therefore there is need
%for developing new decoding algorithms tailored for specific application
%domains.
%
%\todo{Nesedi poradie argumentov, skontroluj to v celej minimovke!}
%Since the correct annotation/state path is unknown, we treat correct annotation
%as a random variable with distribution $\prob{\Lambda\mid X,H}$. We define gain
%function $f:\bar{\Lambda}\times\bar{\Lambda}\to \mathbb{R}$.
%$f(\Lambda_1,\Lambda_2)$ is the ``measure'' of an approximation of $\Lambda_2$
%by $\Lambda_1$. This function is not mathematical measure, it can be arbitrary
%function. Function $f$ is application specific, it should reflect the features
%that are we interested in.
%
%After defining function $f$, we seek the for the annotation $\Lambda$ with the highest expected gain:
%\[\Lambda = \arg\max_{\Lambda} 
%E_{\Lambda_X\mid X,H}[f(\Lambda_X,\Lambda)] =
%\sum_{\Lambda_X}f(\Lambda_X,\Lambda)\Pr\left(\Lambda_X\mid X,H\right)
%\]
%We have shown that problem of finding the annotation with the highest expected
%gain given sequence $X$ and annotation function $f$ is NP-hard. However, some
%gain functions can be decoded in polynomial time (for example gain functions for
%the Viterbi algorithm or gain function for  the Posterior decoding). 

\todo{este raz si toto po sebe precitaj}
Alternative
decoding functions can improve the annotation algorithm as has been shown in
\cite{Nanasi2010,Truszkowski2011} for the HIV virus recombination detection.
We want to continue study these function for the virus recombination domain. We
want to explore the  possible extensions by restricting of the structure of the
possible annotation (restriction on the labels that can be in the annotation, or
in general restrict it by a regular expression).

Whilei we plan to further study gain functions for the virus recombination
problem, we want to focus on extensions of the highest expected gain framework to
pair hidden Markov models and develop gain functions (and decoding algorithms
that maximize such functions) tailored to the pairwise alignment problem. 

To extend the highest expected gain framework to pHMMs, we need to extend
definition of an annotation. In general, pHMMs are used for annotation and
comparison of two sequences at once. In comparative gene finding, a pHMM is used
to find genes in both sequences, and actual alignment is not main issue. In
other applications, we are not so much interested in the annotation of the
sequences, but rather in relation between the symbols of the two sequences. A
state path of a pHMM uniquely assigns annotations to the the input sequences and
also defines a unique alignment.  Therefore we could define annotations in same
way as for HMMs as a simple mapping from the set of states to the set of labels.
If we do so, it will create the following problem.

Let $H$ be the simple  three state pHMM for sequence alignment from figure
\ref{FIGURE:SIMPLEPHMM}. Let $C=\{M,I\}$ be the set of labels and $\lambda$ be
annotation function, such that $\lambda(M)=M, \lambda(I_X)=I$ and
$\lambda(I_Y)=I$.   For example let $X=Y=ACGT$ and $\Lambda = IIMMII$.  In this
case it is not possible to assign annotation symbols to input sequences $X$ and
$Y$ and it is not even possible to assign unique alignment.  Then following $6$
alignments are possible:
\begin{verbatim}
Annotation:    IIMMII    IIMMII    IIMMII    IIMMII    IIMMII    IIMMII
X:             --ACGT    ACGT--    A-CGT-    A-CG-T    -ACGT-    -ACG-T
Y:             ACGT--    --ACGT    -ACG-T    -ACGT-    A-CG-T    A-CGT-
\end{verbatim}
And following three annotations of $X$ and $Y$ are possible: $MMII,IMMI,IIMM$.

Note that the last four  alignments are equivalent -- they only differ in the order
of indels in sequences. All symbols from both $X$ and $Y$ can be aligned to a gap
or to some symbol in other sequence. All symbols from both sequences can be
annotated by $I$ or $M$. Therefore such an annotation does not give us much
information.
For this reason we propose the following the definition of the annotation
function for  pHMMs.

\todo{ujednotit annotation function, labeling function a coloring function}
\begin{definition}
Let $H=(\Sigma,V,I,d,e,a)$ be a pHMM and $C=\{c_0,c_1,\dots,c_{l-1}\}$ be the
finite set of labels (or colors). The \firstUseOf{coloring function}
$\lambda:V^*\to C^*$ is function that satisfies following properties: 
\begin{enumerate}
\item $\lambda(v)\in C$ for all $v\in V$.
\item $\lambda(xy) = \lambda(x)\lambda(y)$ for all $x,y\in V^*$.
\item If $\lambda(u)=\lambda(v)$ then $d^x_u=d^x_v$ and $d^y_u=d^y_v$ for all
$u,v\in V$.
\end{enumerate}
Let $X$ and $Y$ be sequences generated by a state path $\pi$. Then the
\firstUseOf{pairwise annotation} of sequences $X$ and $Y$ is 
$\Lambda=\lambda(\pi)$.
\end{definition}

Note that this definition is almost the same as the definition of an annotation
for HMMs (definition \ref{DEFINITION:ANNOTATION}),  
with addition of the  third condition, which ensures that
the annotation keeps information about state duration $d$. Therefore we are able to
derive a unique alignment from an annotation and uniquely assign colors to symbols of
input sequences.

Similarly as with the HMMs, sequences $X$ and $Y$ and pHMM $H$ define
a probability distribution of pairwise annotations $\Lambda$
\[\prob{\Lambda\mid X,Y,H} = \sum_{\pi,\lambda(\pi)=\Lambda}\prob{\pi\mid
X,Y,H}\]

We can also define a gain function as any function $f:C^*\times C^*\to
\mathbb{R}$. In the  highest expected gain problem for pHMM, we search for
the pairwise annotation $\Lambda$ of input sequences $X$ and $Y$ that maximizes
the expected gain:
\[\Lambda = \arg\max_{\Lambda} E_{\Lambda'\mid X,Y,H}[f(\Lambda',\Lambda)]
=  \arg\max_{\Lambda} \sum_{\Lambda'}f(\Lambda',\Lambda)\prob{\Lambda'\mid X,Y,H}\]

Similarly as with HMMs, finding the most probable pairwise annotation (which is equivalent
to finding the most probable state path if $\lambda$ is identity function),
is equivalent to finding the  pairwise annotation with the highest expected gain with
gain function
\[f_{ID}(\Lambda',\Lambda) = \begin{cases}
1 & \text{if $\Lambda'=\Lambda$}\\
0 & \text{otherwise}
\end{cases}\]
To our knowledge, with the pairwise alignment only the Viterbi algorithm (the
most probable state space) or the Posterior decoding was used
\cite{Lunter2008}.
%In this case, the expected gain of an pairwise annotation $\Lambda$ is
%equivalent to the probability of $\Lambda$ and therefore by maximizing the
%expected gain we also maximize the probability $\prob{\Lambda\mid X,Y,H}$.

Our goal is to develop and study gain function that can be used for pairwise
alignments. Alignments constructed with such gain function (combined with new
models described in section bellow) should have better quality: fewer biases,
higher sensitivity and lower false positive ratio of the aligned residues.
Of course we have to design gain functions in a way that optimizing them will
be computationally tractable.

One possible extension is to extend the Posterior decoding to mode columns: 
the gain function is the number of correctly predicted $k$-tuples from the
alignment. Other possibility is to address the gap wander and gap attraction
biases. Lunter {\it et al.} reported that the average sequence identity near
gaps was higher then the expected value and with the distance from the gap
the expected sequence similarity lower almost to the correct value. To address
this issue, the gain function should penalize the gaps, that are near other
gaps, by lower ``gap penalty'' then the standalone gaps.

%One possible way how to improve gain function for decoding hidden Markov models
%is to allow  . In the study of Lunter {\it et al. (2008)} why found out that the
%average sequence identity near gap was higher due to gap wander and gap
%attraction bias. The gap attraction bias could be Other option is to consider 

\section{Models for Pairwise Sequence Alignment}

Currently used pair hidden Markov models that are used for sequence alignment
does not address all important aspects of the sequence evolution. As we discuss
in chapter \ref{CHAPTER:PAIRHMM}, novel models address different rates of
evolution or use better gap models. However, genome to genome aligners does not
use for example the information about structure of genes. We want to incorporate
into model gene structures similarly as the protein to genome aligners or
comparative gene finders discussed in chapter \ref{CHAPTER:PAIRHMM}.
Specifically, we want to adjust our pHMM to  address following issues: 

\paragraph{Gene structure:}  protein/cDNA to genome aligners or comparative gene
finders used strict gene structures in order to detect genes and annotate them
or align other sequences to it.  However, in alignment we are also interested in
parts of sequences that are not genes, for example pseudogenes. Pseudogenes are
former genes that were disabled during evolution. They have similar structure to
genes, but structure of pseudogenes is broken in some way (for example missing
signals like start codons, splice sites or others). Therefore out model have to
take into consideration also parts of the sequence that does not conform the
gene structure.

%the structures that are inside genes Therefore we need to
%relax gene structure and allow also For example structure pseudogenes
%(preudogenes are former genes that were somehow disabled) does not have to
%conform structure of real genes.  Therefore the model that relies on the gene
%structure does not have to be ideal.  

\paragraph{Variable substitution rate:} evolution distance between different
organisms is not constant.  Therefore our model has to be parametrized by the
evolution distance of aligned sequences to adjust the substitution probabilities
without need to train model on new organism. As described in chapter
\ref{CHAPTER:PAIRHMM} substitution rate in genome differs for different parts of
the model.  Additionally, substitution rate may vary in relatively short
regions, for example within one gene.  To address this issue, the model should
contain several sub-models that are trained to different evolution rate as in
\cite{Hudek2010}.

\paragraph{Gap models:} Gaps are usually modeled with geometric distribution
or with the two component mixture model since they are easy to incorporate into 
pHMMs. As we have seen in section \ref{SECTION:CONVEX}, convex gap functions
does not imply hight computational overhead. By extending algorithm from section
\ref{SECTION:CONVEX} to pair hidden Markov models we can create more realistic
models with reasonable increase of algorithm's running time.


\label{LastPage}

%Traditionally used algorithm for decoding \abbreviation{Hidden Markov
%Models}{HMMs} is Viterbi \todo{Aj tak si myslim, ze cele toto by som asi mal
%presunut o kapitoly vyssie}
%algorithm. \abbreviation{Viterbi algorithm}{VA} finds the most probable state path, which is
%state path $\pi$ that maximizes $\Pr\left(\pi \mid X\right)$. Other commonly
%used criteria, the \abbreviation{Posterior Decoding}{PD}, is maximizing the sum of the posterior
%probability for every state in state sequence independently. Therefore PD finds
%the state path $\pi$ that maximizes $\sum_{i=1}^{|\pi|} \Pr\left(\pi_i \mid
%X\right)$ \todo{Trosku upravit oznacenia vo vzorcoch}. Both VA and PD can be
%computed in effectively in $O(NM)$ time and memory, where $N$ is the
%length of the sequence and $M$ is the size of the model (number of states plus
%number of transitions). There are also couple of tricks how to lower the memory
%requirements of such algorithms or even exploit repetition of the sequences to
%decrease running time.
%
%In some practical HMMs some states have same role (i.e. they encode same thing)
%\todo{chcelo by to predtym poriadne zaviest co su anotacie a tak -- este v
%prehlade}
%but for some reasons can not be merged into same states. Therefore does not have
%to distinguish between state paths, that differs only in those states. In
%general, we can assign to each state annotation symbol (or "color") and we want
%to account into probability of some state path $\pi$ probabilities of all state
%spaces, that has same sequence of annotation symbols. Therefore we are
%maximizing following criteria
%\[\sum_{\pi'\textrm{ has same annotation as }\pi}\Pr\left( \pi' \mid X \right)\]
%
%However, maximizing such criteria is NP-hard \cite{} and even if we fix the
%HMM \cite{Brejova2005}. Since maximizing this criteria is not tractable, we have
%to use some heuristics that can possibly find only local maxima. It possible to
%find HMM, for which VA finds annotation that has exponentially smaller
%probability than the most probable annotation. Similarly, since PD maximizes
%each state in state path independently, it can reconstruct state path/annotation
%that has zero probability.
%
%We can generalize all those into framework in which we will define gain function
%and where we are trying to find annotation that has highest possible gain with
%respect to correct annotation. Since we do not know the correct annotation, we
%are treating the correct annotation as an random variable with distribution
%$\Pr\left(\cdot\mid X\right)$. We can express all decoding methods that are
%described above in terms of gain functions and therefore finding the annotation
%with the highest expected gain (if gain function is computable function) is
%NP-hard. But some HMM's and gain functions we can find annotation with the
%maximum expected gain in polynomial time. 

%-- proste ze chceme sa venovat takym veciam, ze ktore funkcie sa daju pocitat
%efentivne a ktore nie. A podobne.

%Gain functions described above are not the only ones that can be in practice
%used. There are several ??

%+ extend those measures to pair-hidden Markov Models


%nieco o mierach -- vo vseobecnosti niektore miery su NP-tazke, 
%vo vseobecnosti to moze byt az nerozhodnutelne -- redukcia na PKP, alebo nieco
%take.
%
%Rozne miery su vhodne pre rozne situacie -- niekedy chceme len lokalne
%vlastnosti,  niekedy globalne, optimalizujeme rozne funkcie, nie vsetky
%vlastnosti su zachytene modelom (otazka: preco potom radsej nechceme zmenit
%model?) 

%Hidden Markov models are extensions Markov chains \ref{Levin2006}. Markov chain 
%is the sequence of random variables $X_0,X_1,\dots$ with property that $X_i$
%depends only on $X_{i-1}$. This property is called Markov property:
%\[\prob{X_i\mid X_0,X_1,\dots,X_{i-1}}=\prob{X_i\mid X_{i-1}}\] If state of
%Markov chains if finite, then every chain can be characterized by the transition
%matrix $P[i,j]=\prob{X_k=j\mid X_{k-1}=i}$ (this transition matrix is same as
%for the HMMs). Markov chain is \firstUseOf{ergodic} if there exists $n_0$ such
%that for all $n>n_0$ $P^n[i,j]>0$. Ergodic Markov chain has stationary
%distribution $p$ with property, that $\lim_{n\to \infty}$
%
%Mixing time is the probability that 
%
%
%We want to study 
%We would like to fill this gap and prove that for certain classes of HMMs,
%the average memory complexity is logarithmic or polylogarithmic in the length of
%the input sequence. Since there are 

%that for large HMM
%foe gene finding the average memory requirements were polylogarithmic.

%Memory requirements of uncompressed tree are same
%as for the compressed tree: because in compressed version we still remember
%the sequences of states on the edges. Compressed version reduces memory
%requirements only by constant factor. 



%For example we can reduce the memory
%footprint of the Viterbi algorithm by discarding 

%Similar approach is used in Treeterbi algorithm. There is also variant of this
%technique, that improve memory footprint of k-best algorithm. This approaches
%works in practice, but 

%However analysis of such algorithm consists of 

%+ extend to pHMM

%* Vyut niektore teoreticke vlastnosti na zlepsenie algoritmov -- pamatova
%narocnost,

%Ako sa daju vylepsiet terajsie algoritmy -- cez mixing time -- napriklad
%ak vypocitame mixing time pre model -- definovat sa na napriklad tromi sposobmi
%-- najhorsia sekvencia, nahodna (uniformna) alebo nahodna z modelu.
%Neda sa to robit normalne, lebo nevieme ako vyzera sekvencia. Ale vieme robit
%napriklad normalizovany forward -- teda ako velmi sa budu lisit tieto sekvencie
%aj zafixujeme sekvenciu -- alebo predpokladame ze je nahodna.

%Definovane rovnako ako mixing time -- rozdiel distribucii --

%Takto vieme spravit trenovanie rychlejsie -- jednak ho vieme 
%lahsie distribuovat, dvak vieme znizit pamatovu narocnost. Vieme nieco spravit
%napriklad pre Viterbiho? Da sa urcit nieco z modelu? 


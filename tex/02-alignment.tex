\chapter{Alignment}
\begin{note}
Prerekvizity: co je to sekvencia DNA, pripadne sekvencia proteinu
\end{note}
\section{Definitions}

Parts of two sequences are homologous, if they have evolved from same part of
their ancestral sequence. Aim of sequence alignment is to identify homologous
sequences. There are several evolution events, that usually happens:
mutation of residue into another residue, deletion of part of the sequence,
insertion of residues into the sequence. We omit rearrangements of sequence,
because it cannot be represented by alignment. Alignment is one way of
representing of comparisons of two sequences. We obtain alignment of $k$
sequences by inserting dashes into sequence in a way, that they will have same
length. Therefore we can represent alignment as matrix or table. Row of the
alignment is a sequence with inserted dashes and column is list of residues from
all row on certain position.

Alignments have biological meaning. We try to create alignment in a way, that
homologous residues are in same row. Dashes represents either the parts of
sequence that were deleted during evolution (deletions) or that on those
positions were inserted some sequences to other sequence (insertions). If we
have alignment of sequences from current organisms then without some prior
knowledge it is not possible to distinguish between insertions and deletions.
Therefore we will refer to those as to indels.

\begin{example} 
Consider following evolution history of hypothetical DNA sequences of two current organism $X$ and $Y$:
\begin{verbatim}
X:      C C     G C G A C C T T G C             A C C A
X':     C C     G           T T G C             A G C A
P:      A C T G G           T C G C T G A G C T A G C A
Y':     T C T G G           C C           G C T A G C A
Y:      T C T A G           C C           G A T A G C A
\end{verbatim}
$X$ and $Y$ evolved from parent sequence $P$ through sequences $X'$ and $Y'$.
During evolution from $P$ to $X'$, four events occurred: deletion of 
sequences ``TG''  and ``TGAGCT'' and mutations of two bases. Evolution of $X$
was ended by  
positions bases were substituted. In change from $X'$ to $X$, one base was
changes and siequence ``CGACC'' was inserted.  Similarly, from 
REmove this paragraph

\begin{verbatim}
X:      C C     G C G A C C T T G C             A C C A
Y:      T C T A G           C C           G A T A G C A
\end{verbatim}
We obtain actual alignment by removing columns that contains only gaps a
replacing gaps with dashes (gap symbols). 
\begin{verbatim}
X:      C C - - G C G A C C T T G C - - - A C C A
Y:      T C T A G - - - - - C C - - G A T A G C A
\end{verbatim}
If two residues are in same column in alignment then they are homologous.
Being homologous does not tell that those symbols are equal. 
\end{example}

There is only one alignment that reflects evolution history. Our goal is to find
this alignment, or at least find the alignment, that is as close as possible.
\correction{We
will consider only pairwise alignments (alignments of two sequences).}{Urvat ak
zacneme robit multiple}


\section{Scoring Schemes}

Since we want to construct alignments that have biological meaning, we have to
develop a way, how to assess the quality of an alignment. On way of doing it is
to define scoring scheme. There are many ways how to develop good scoring
scheme. We will assess 

\todo{Local vs. global alignment}
\section{Needleman-Wunsch algorithm}

Alignment with scoring scheme with previous section can be found by
Needleman-Wunsch algorithm. 
%TODO: nieco o tom ze to bol povodne kubicky, ale sankoff spravil lepsiu verziu

This algorithm uses score table $S$, affine gap model with gap penalty $d$ and
gap opening penalty $g$ is zero. To align sequences $X$ and $Y$ with length $n$
and $m$ respectively, we define matrix $M$ of size $n\times m$. $M[i,j]$ will be
the score of the best alignment of sequences $X[:i]$ and $Y[:j]$. We can compute
$M[i,j]$ by following equations:

\begin{align}
M[0,0] &= S(X_0,Y_0)\\
M[0,i] &= i\cdot d, 0< i < m\\\
M[i,0] &= i\cdot d, 0< i < n\\
M[i,j] &= \max
\begin{cases}
 M[i-1,j-1]+S(X_i,X_j)\\M[i,j-1]+d\\
 M[i-1,j]+d
\end{cases}, 0<i<n,0<j<m \label{ALIGN:ALGO:AFFINE}
\end{align}

By computing $M[n-1,m-1]$ we have the score of the alignment of $X$ and $Y$ with
the highest score. We can reconstruct such alignment by back-tracing matrix $M$.
Matrix 

To cope with gap opening penalty, we have to slightly change the algorithm.
We define two other matrices $M_X$ and $M_Y$ of same size as $M$. $M_X[i,j]$
will contain the score of alignment of sequences $X[:i]$ and $Y[:j]$ than ends
with gap in sequence $X$. $M_Y$ is analogous. Now we show how to compute $M,M_X$
and $M_Y$. \todo{Skontroluj to! Navyse som si nie isty ci affine nie je len bez
$g$ a s $g$ je to generalized affine}

\begin{align}
M[0,0] &= S(X_0,Y_0)\\
M[0,i] &= M_X[0,i] = i\cdot d+g, 0 < i < m\\
M[i,0] &= M_Y[i,0] = i\cdot d+g, 0 < i < n\\
M[i,j] &= \max
\begin{cases}
 M[i-1,j-1]+S(X_i,X_j)\\
 M[i,j-1]+d\\
 M[i-1,j]+d\\
 M_X[i,j]\\
 M_Y[i,j]
\end{cases}, 0<i<n,0<j<m\\
M_X[i,0] &= -\infty, 0\leq i< n\\
M_Y[0,i] &= \infty, 0 \leq i< m\\
M_X[i,j] &= \max
\begin{cases}
M[i-1,j]+g+d\\
M_X[i-1,j]+d
\end{cases}, 0<i<n,0<j<m\\
M_Y[i,j] &= \max
\begin{cases}
M[i,j-1]+g+d\\
M_Y[i,j-1]+d
\end{cases}, 0<i<n,0<j<m
\end{align}
\todo{Je vlastne vobec treba taketo vypisovat?}
As in previous case, values of $M,M_X$ and $M_Y$ can be computed by simple
dynamic and by back-tracing these matrices we can obtain optimal alignment of
$X$ and $Y$.
Both algorithms have time complexity of $O(nm)$ and memory complexity $O(mn)$.
Using tricks described in later section, the memory and even time comple

\section{Dynamic Programming}

For simplicity, we will assume that both sequences has same length $n$. This
will allow us to express complexity in simple way.  At first we show how
to compute compute those algorithms in $O(n^2)$ time and $O(n^2)$ 

In this section we show how to compute
those values effectively and describe \correcction{four}{Subject to change}
methods how to decrease memory footprint and/or time complexity. Needleman-Wunch
algorithm can be computed by following code. Note that $F$ is function, that
computes value of $M[i,j]$ as in equation \ref{ALIGN:ALGO:AFFINE}.

\begin{lstlisting}
Initialize M[i,0] and M[0,i]
for i in 1...n-1
  for j in 1...n-1
    M[i,j] = F(M[i-1,j-1],M[i-1,j],M[i,j-1])
i = j = n - 1
while i > 0
  (i,j) = F'(M[i-1,j-1],M[i-1,j],M[i,j-1])
  print (i,j)
\end{lstlisting}

Lines 2-5 fills matrix $M$ and lines 6-8 implements the back-tracing procedure.
From printed positions we can reconstruct alignment easily (move in diagonal
corresponds to aligned bases, move in other direction corresponds to gap).


\subsection{Checkpointing}

Checkpointing is general trick in dynamic programming, that allows us to save
$O(\sqrt n)$ rows of dynamic programming matrix while doubling running time.
We will treat matrices $M,M_X$ and $M_Y$ as one matrix containing triples.

In order to compute $i$-th row of matrix $M$, we need only row
$i-1$. As mentioned above, to compute just the score of the best alignment we
need to remember only two rows (previous and current which are we trying to
compute). However, if we want to back-trace the optimal alignment, after we
compute it's score, we need all those rows of matrix $M$ again so we would have
to compute them again. Since we need for back-tracing rows in decreasing order,
this would lead to $O(n^4)$ time, since every time we need previous row, we
would have to recompute it from beginning.

Checkpointing solves this problem by remembering every $k$-th row of matrix $M$.
For this we need to remember $\lceil n/k\rceil$ rows.
While backtracing, we will remember additional block $B$ of consecutive $k$ rows in
some interval $<ik,(i+1)k-1>$. We can compute such block on $O(kn)$ time. 
If we need row that is outside $B$, we replace block $B$ with block that contain
such row. Since we access every row only once and in decreasing order, we
recompute every block at most once. Therefore time complexity of back-tracing
will be $O(n^2)$. We have to remember every $k$-th row and one block of size
$k$, so memory complexity is $O(\lceil n/k\rceil n+ kn)$. If we set $k=\sqrt n$
then memory complexity will be $O(n\sqrt n)$ while time complexity will remain
same.


\subsection{Hirschberg Algorithm}

Hirschberg algorithm is divide and conquer approach to reduce memory
requirements of sequence alignment. Idea is following.: Let $L()$ be algorithm, 




Let $(i,j)$ be the cell in the matrix $M$, that will be intersected by
back-tracking procedure. That means, that value $M[n-1,n-1]$ was computed 
from $(i,j)$ and therefore submatrices $M[0:i,j+1:n]$ and $M[i+1:n,0:j]$
are not necessary for computation of best alignment and we do not have to
compute them. If $i=n/2$ then we 


Hirschberg Algorithm (HA) reduce memory more than checkpointing, but HA can be
only applied to algorithms that use back-tracing. For example Forward-Backward
algorithm can be improved by checkpointing but not by HA. More in chapter TODO.

\subsection{Exploiting Sequence Repetition}

This technique reduce time complexity of alignment algorithm to $O(n^2/log n)$.
Unlike four-russian trick \cite{}, this technique enables usage of any cost
matrix.  This idea combines LZ78 factorization \cite{} and $O(A+B)$ algorithm
for computing row minima/maxima in totally monotone matrix of size $A\times B$\cite{}. 

LZ78 factorization divide sequence $S$ into $k$ strings $S_0,\dots,S_{k-1}$, where
$S_1S_2\dots S_k=S$ and for every index  $i,0< i <k$ there is index $0\leq j<i$
such that $S_j$ is prefix of $S_j$ of size $|S_i|-1$. We will call $S_j$ to be a
predecessor of $S_i$. We have guarantee, that $k$ is in $O(\frac{n}{log n})$
\cite{}. If we want to align sequences $S$ and $T$, we factorize $S$ and $T$
into sequences of strings $\{S_i\}_{0\leq i < k_s}$ and $\{T_i\}_{0\leq i<
k_t}$. Every pair $(S_i,T_j)$ defines rectangular block of matrix $M$.
We say that $(S_k,T_l)$ is predecessor of $(S_i,T_j)$ if one of the folowing
conditions is true:

\begin{itemize}
\item $S_k$ is predecessor of $S_i$ and $l=j$
\item $k=i$ and $T_l$ is predecessor of $T_j$
\item $S_k$ is predecessor of $S_i$ and $T_l$ is predecessor of $T_j$
\end{itemize}

Computation in blocks. 

\subsection{Restricting Search Space}

Another approach how to decrease running time (and memory requirements) is to 
restrict search space in which we search for best alignment.
There are several approaches how to do that. If the sequence 


\section{Non-Affine Gap Models} 

Reason why affine gap models are used in sequence alignment is because they are
simple, easy to compute and gave reasonable results. While affine gap score
works fine for short gaps, it gave too high score for the TODO

Let $f(x)$ be the gap penalty where $x$ is the length of the gap. In case of
affine gap models, $f(x)=g+dx$. In case of general gap function, we have to
reformulate equation \ref{ALIGN:ALGO:AFFINE} in following way:
\begin{align}
M[i,j] &= \max
\begin{cases}
 M[i-1,j-1]+S(X_i,X_j)\\
 M[i,j-y]+f(y)\\
 M[i-x,j]+f(x)
\end{cases}, 0<x\leq i<n,0<y\leq j<m
\end{align}
This algorithm has time complexity of $O(n^3)$ where $n$ is the length of the
longest sequence. Note that this was the original Needleman-Wunsch\cite{}
algorithm and later ?? improved algorithm for affine gap functions\cite{}.
Unlike previous recursive equations, int this algorithm $M[i,j]$ depends not
only on neighbouring cells, but also on all previous in same row and column.
Therefore just computation 

\subsection{Convex Gap Functions}

Now we describe algorithm to compute best alignment with convex gap function.
Function $f(x)$ is convex, if and only if
\[f(x+y)\leq f(x)+f(y)\]
 

%tu chcem definiciu convexnej gap funkcie
%algoritmus ktory je v case n^2 log(n)
%algoritmus, ktory bezi v case n^2 alpha(n)
%kubicky algoritmus v worstcase, ale prakticky konstantny (budem musiet najst 
%citaciu -- nepodarilo sa mi to najst. Zaujimave\ldots)



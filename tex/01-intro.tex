\chapter{Introduction}

\begin{reformulate*}
Co vlastne chcem povedat
\begin{itemize}[itemsep=-1mm]
\item Chcem mat uvod ako aj pre niekoho kto nerozumie nicomu z biologie
\item ako aj pre niekoho kto nerozumie vela z informatiky
\item Uvod do zakladnych veci, ako dna, sekvencia, baza, mozno evolucia
\item Co vlastne v tejto praci je -- co sme spravili, co sme vylepsili a podobne
\item Ako vyzera struktura prace
\item Oznacenia?
\end{itemize}
\end{reformulate*}

In this thesis we focus on the computational methods for comparative analysis
and annotation of biological sequences. We propose new methods that produce
alignments and annotations with higher quality. We also study the computational
complexity of the decoding algorithms and give proofs of NP-hardness for some
decoding methods. 

New technologies are giving us the ability to produce more and more data, the
automated analysis of such data is necessary and therefore it is important to
develop such tools. We will study both sequence annotation problem and the
sequence alignment problems. \todo{BLABLABLA}

Now we try to explain the sequence annotation and the sequence alignment from
the computational scientists perspective. We work with generative probabilistic
models, the \abbreviation{hidden Markov Models}{HMM} and their variants. In
general, HMMs are state machines that generates sequence (string) along the
sequence of states (called state path) that was used for generating the
sequence. Since HMM is an probabilistic model, it also defines the probability
of the sequences and the state paths. The state path contain the information
about the structure of the generated sequence. In practice we are given the
generated sequence and the state path is hidden. In sequence annotation, we
group the states of HMM into several classes (called labels, or colors) and the
state path into sequence of labels abstracting from the specific details of the
generation process. Advantage of using the probabilistic models is that apart
from the distribution of the sequences and state paths, we also obtain the
distribution of the annotations. The goal of the decoding algorithm is to
reverse the generation process and obtain the original state path or at least
the annotation. 

When using HMMs for annotation of the biological sequences, we construct HMM in
a way, that the structure of states corresponds to the biological features we
are interested in (feature is usually the biological function of the sequence).
Then we use the decoding algorithm to obtain the state path or an annotation in
such a way, that the result is as close as possible to the true state path or
an annotation. Traditionally used decoding algorithm is the Viterbi algorithm
\cite{}, but other optimization criteria can be used to obtain more
accurate\footnote{Where an accuracy is a some measure that depends on the
application domain.} results \cite{}. In Chapter \ref{} we will study the
computational complexity of some decoding criteria and show NP-hardness for
obtaining the optimal alignments using these criteria. Namely we study the most
probable footprint problem, the problem of the most probable set problem and
the most probable restriction problem. All these problems are parts of the
decoding criteria for the HMMs.

In the sequence alignment problem, our goal is to compare the biological
sequence and find related parts of the sequences (what doest the term related
sequences means will be explained in Section \ref{}). This is usually done by
constructing the sequence alignment, which is the representation of the
comparison of two sequences; sequence alignment is obtained by adding gap
symbols ($-$) into the sequences so that they have the same length and that the
related parts of the sequences are in the same positions. The simplest
approximation of the relatedness is the sequence identity. We could add 
the gap symbols into sequence in order to maximize the number of matching positions.
For example for sequences $X=ACGTTG$ and $Y=AGTTAAA$, we can have $4$ matching positions (or columns):
\begin{verbatim}
X: ACGTTG--
Y: A-GTTAAA
\end{verbatim}
This was the first example of the sequence alignment with the simple scoring
scheme: the number of matching columns. In practice, scoring schemes for
alignment are 

This is very very simplified model and does not reflect the 
\begin{reformulate*}
vieme dat pomlcky tak, aby sme maximalizovali pocet zhod na rovnakom mieste.
Napriklad pre vstupne sekcencie....

Rovnako vieme pouzit edit distance, pripadne skorovat substitucie rozne, a pridat aj medzery.
Taketo skorovacie schemy sa pouzivaju a funguju prekvapujuco dobre, ale stale obsahuju 
chyby lebo biologia je ovela komplikovanejsia. Tieto schemy vedia byt vyjadreme pomocou 
pHMM, ktore generuju dvojice sekvencii (a zaroven zarvonanie) a pri dekodovani sa
snazime tento proces reverznut. Avsak tieto casti nam umoznuju zakomponovat do
modelu dalsie evolucne operacie, cim sa spresni zarovnanie.
Rovnako mozeme vybrat vhodny dekodovaci algoritmus.

V tejto praci sme sa zamerali na tandemove repeaty, ktorych je v DNA vela a sposobuju problemy pri zarovnavani.
Navrhli sme model, ako aj dekodovacie ktoeria, ktore skvalitnili zarovnania.

Bilogicke:
Co je DNA, ako vyzera, co je evolucia -- ako to vyzera
ake operacie sa tam zhruba deju, preco pouzivame taketo skorovacie schemy.
Co su repeaty, geny a podobne.
\end{reformulate*}
Therefore the
basic methods for finding the alignments are based on the extension of the edit
distance. These scoring schemes 


Both problems studied in this proposal, annotation and alignment of biological
sequences, can be addressed by variants of \abbreviation{hidden Markov
models}{HMMs}.  Hidden Markov models are generative probabilistic models which
define a probability distribution of sequences with their annotations
\cite{Durbin1998}. An annotation is the assignments of labels to parts of the
sequence according their meaning, The labels can represent biological function,
the origin of a part of the sequence or any other information. HMMs are used for
probabilistic analysis of sequences in various fields. In our work we focus on
biological sequences. 

A decoding algorithm is an algorithm that from the input sequence $X$ and HMM
$H$ computes the annotation of sequence $X$. The goal is to recover the true
annotation of $X$, but finding such an annotation is impossible due to the
randomness in the generating process. Therefore the decoding algorithm finds
some approximation of the true annotation.  In recent years different decoding
methods were developed to improve the quality of annotations
\cite{Gross2007,Nanasi2010,Nanasi2010mgr,Truszkowski2011}.  Additionally there
are many techniques that are used to lower the computational complexity of the
decoding and training algorithms (training algorithms are algorithms that
compute the parameters of the model from a training data set).

In the field of comparative analysis of biological sequences we focus on the
sequence alignment problem. A sequence alignment is a simple data format (or
data structure) that represents the similarities in the sequences. An alignment
is created by inserting dashes ('-') into both sequences in a way that the
sequences have the same length and similar symbols are on the same positions in
both sequences. In computational biology the alignments are constructed in a way
that the homologous parts of the sequences are aligned together. Homologous
sequences are sequences that have evolved from the same part of the sequence of
the ancestral organism.  The reason for searching and studying homologous
sequences is that homologous sequences are expected to have the same or similar
functions in both organisms.  Therefore by studying homologous sequences we can
transfer knowledge about functions from one species to others.

Alignments can be created using a variant of hidden Markov model called
\abbreviation{pair hidden Markov model}{pHMM}. A pHMM  that generates three
objects: two sequences $X,Y$ and their alignment $A$.  By proper decoding method
we can obtain a good approximation of $A$ for given sequences $X$ and $Y$. Our
goal is to study decoding methods and models that are used for sequence
alignment in order to create software that will produce alignments with high
quality.


\section{Biological Introduction}

%\todo{zmen nazov kapitoly}

%DNA,RNA,protein, amino-acid, residue, base, gene -- exon, conod, start codon,
%stop codon, cDNA, intron, splice site, donor, acceptor, intergenic region,
%homolog,


By biological sequences we mean either DNA/RNA sequences, which are finite
sequences over the alphabet $\{A,C,G,T/U\}$ ($T$ is in DNA, $U$ in RNA) or
protein sequences which are sequences over the alphabet of $20$ amino acids.
Later in this chapter we will discuss the relationship between these sequences.


In this section we review several biological terms that will be needed. More
information about DNA, proteins and genes can be found in
\cite{BiologyForDummies,UnderstandingBioinformatics}.  Every cell of living
organisms contains one or several \firstUseOf{DNA} molecules. DNA is a double
stranded molecule, consisting of two long sequences of \firstUseOf{nucleotides}
(nucleotides are also referred to as bases or \firstUseOf{residues}). There are
four types of nucleotides in DNA: adenosine, cytosine, guanine and thymine
represented by letters $A,C,G$ and $T$ respectively. In RNA nucleotide $T$ is
replaced with uracil, denoted by $U$. The strands in DNA are complementary. The
nucleotides at the same position in two strands are connected by hydrogen bonds
and are complementary: $A$ is always connected with $T$ and $C$ is always
connected with $G$. Therefore we can represent DNA by a sequence over alphabet
$\{A,C,G,T\}$. The complementary strand can be easily computed.

DNA encodes \firstUseOf{proteins}. Proteins play an important role in cell
biology since  they regulates many processes in the cell and are catalysts to
many chemical reactions. Proteins are sequences of \firstUseOf{amino acid}
molecules. There are $20$ amino acids that can be encoded in DNA. Parts of DNA
that encode proteins are called \firstUseOf{genes} (gene is ``substring'' of DNA
that will be translated into one protein).

Every gene consists of two types of sequences: exons which encode amino-acids,
and introns are removed before translation (some genes do no have any introns).
At first, double stranded DNA is copied or transcribed into single stranded RNA
called mRNA. Then, the introns are spliced out of mRNA and exons are merged into
one sequence: spliced mRNA. This sequence is then translated into a sequence of
amino-acids (protein). Each amino acid is encoded by a triplet of nucleotides
called \firstUseOf{codon}. Amino acids have multiple representations: different
codons can encode the same amino acid. Since codons are always triplets, the
length of coding region in the  spliced mRNA is multiple of three. However, the
length of individual exons does not have to be multiple of three since introns
can be located inside codons.  The coding sequence of a gene begins with a start
codon (sequence $ATG$) and the last codon of a gene is called stop codon
(sequences $TAG,TAA$ or $TGA$).

An intron begins with 5' splice site (also called donor site),  and ends with 3'
splice site (or acceptor site).  Acceptor and donor sites are sequence motifs of
fixed length \cite{Pairagon2009,UnderstandingBioinformatics}.

\section{Structure}

The structure of this document is following. In the rest of this chapter we
describe necessary biological terms and define several notation used throughout
the text.

In the second chapter we will discuss the sequence alignment problem and methods
that create sequence alignments without using pair hidden Markov models. We
describe basic scoring schemes, algorithms that search for alignments with high
scores and several approaches for improving the computational complexity of such
algorithms.

The third chapter describes hidden Markov models. We define HMMs and review
basic algorithms for decoding. We then discuss the highest expected gain
framework which is a generalization of the well-known decoding algorithms.  We
also define several variants of HMMs: generalized hidden Markov models,
high-order HMMs, pair hidden Markov models and their combinations. In the last
part of the chapter we discuss several algorithmic improvements of standard
decoding algorithms.

The fourth chapter is dedicated to alignment methods  using pair hidden Markov
models and their variants and also to other applications of pHMMs. We review
several pairwise aligners and comparative gene finders and also results
concerning the quality and biases in the alignments.

The fifth chapter contains our PhD project with the proposed directions for our
research. We want to focus on the improvements and the analysis of the decoding
algorithms and their application to the sequence alignments. 

\section{Notations}

In this section we summarize notation used in the following
chapters.

All sequences, members of sets, vectors, and rows and columns of matrices will
be indexed from $0$. We will use mostly right-open intervals: $I=[a,b)$ means
that $a\in I$, but $b\notin I$. 

The element at the $k$-th position (zero based) of string (or sequence) $s$ will
be written as $s[k]$. The substring $s[i]s[i+1]\dots s[j-1]$ is denoted
$s[i:j]$.  If $n$ is the length of the string $s$ then $s[:i]$ is equivalent to
$s[0:i]$ and $s[i:]$ is equivalent to $s[i:n]$.  We will use the terms sequence
and string interchangeably.

Let $M$ be a matrix. Then $M[i,j]$ is the element from the $i$-th row and $j$-th
column of $M$ (indices are zero based). Similarly as for strings, submatrix
$M[i:j,k:l]$ is a matrix consisting from the intersection of rows $i,i+1,\dots,
j-1$ with columns $k,k+1,\dots,l-1$. If $M$ is of size $n\times m$ then
$M[:i,j:]$ is equivalent to $M[0:i,j:m]$.  The term $M[i,:]$ is equivalent to
$M[i,0:m]$ which is the $i$-th row of $M$.
